{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76fbaa9-ae15-4bba-bde6-c9b1021cdbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visitor/anaconda3/envs/1DCNN/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epoch=0, n_epochs=20, dataset_name='dataset/facades', batch_size=32, lr=0.0003, b1=0.5, b2=0.999, decay_epoch=3, n_cpu=2, img_height=1024, img_width=256, channels=1, sample_interval=100, checkpoint_interval=-1, n_residual_blocks=9, lambda_cyc=10.0, lambda_id=5.0)\n",
      "['5.npy', '1.npy', '12.npy', '2.npy', '4.npy', '8.npy', '15.npy', '9.npy', '6.npy', '10.npy', '13.npy', '7.npy', '11.npy', '3.npy', '14.npy']\n",
      "['5.npy', '1.npy', '12.npy', '2.npy', '4.npy', '8.npy', '15.npy', '9.npy', '6.npy', '10.npy', '13.npy', '7.npy', '11.npy', '3.npy', '14.npy']\n",
      "Namespace(batchSize=1, dataroot='dataset/facades', channels=1, n_residual_blocks=9, size=1024, cuda=True, n_cpu=8, generator_A2B='save/dataset/facades/G_AB_19.pth', generator_B2A='save/dataset/facades/G_BA_19.pth')\n",
      "['5.npy', '1.npy', '12.npy', '2.npy', '4.npy', '8.npy', '15.npy', '9.npy', '6.npy', '10.npy', '13.npy', '7.npy', '11.npy', '3.npy', '14.npy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import itertools\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "############################  datasets.py  ###################################\n",
    "\n",
    "## 如果输入的数据集是灰度图像，将图片转化为rgb图像(本次采用的facades不需要这个)\n",
    "def to_rgb(image):\n",
    "    rgb_image = Image.new(\"RGB\", image.size)\n",
    "    rgb_image.paste(image)\n",
    "    return rgb_image\n",
    "\n",
    "## 构建数据集\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):          ## (root = \"./datasets/facades\", unaligned=True:非对其数据)\n",
    "        self.transform = transforms.Compose(transforms_)                                ## transform变为tensor数据\n",
    "        self.unaligned = unaligned\n",
    "        \n",
    "        self.each_label = 200\n",
    "        self.A = None\n",
    "        self.B = None\n",
    "        \n",
    "        for data_dir in root:\n",
    "            f_list = os.listdir(data_dir + \"/clean_npy/\")\n",
    "            print(f_list)\n",
    "            for idx in range(len(f_list)):\n",
    "                if self.A is None:\n",
    "                    self.A = np.load(data_dir + \"/clean_npy/\" + str(idx+1) + '.npy').astype('float')\n",
    "                    self.B = np.load(data_dir + \"/noisy_npy/\" + str(idx+1) + '.npy').astype('float')\n",
    "                else:\n",
    "                    self.A = np.concatenate((self.A, np.load(data_dir + \"/clean_npy/\" + str(idx+1) + '.npy').astype('float')))\n",
    "                    self.B = np.concatenate((self.B, np.load(data_dir + \"/noisy_npy/\" + str(idx+1) + '.npy').astype('float')))\n",
    "    def __getitem__(self, index):\n",
    "        curve_A = self.A[index].astype(np.float32)               \n",
    "        curve_B = self.B[index - (index % self.each_label) + random.randint(0, self.each_label-1)].astype(np.float32) # 随机选择对照\n",
    "        return {\"A\": curve_A, \"B\": curve_B}\n",
    "\n",
    "    ## 获取A,B数据的长度\n",
    "    def __len__(self):\n",
    "        return self.A.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "############################  models.py  ###################################\n",
    "\n",
    "## 定义参数初始化函数\n",
    "def weights_init_normal(m):                                    \n",
    "    classname = m.__class__.__name__                        ## m作为一个形参，原则上可以传递很多的内容, 为了实现多实参传递，每一个moudle要给出自己的name. 所以这句话就是返回m的名字. \n",
    "    if classname.find(\"Conv\") != -1:                        ## find():实现查找classname中是否含有Conv字符，没有返回-1；有返回0.\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)     ## m.weight.data表示需要初始化的权重。nn.init.normal_():表示随机初始化采用正态分布，均值为0，标准差为0.02.\n",
    "        if hasattr(m, \"bias\") and m.bias is not None:       ## hasattr():用于判断m是否包含对应的属性bias, 以及bias属性是否不为空.\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)       ## nn.init.constant_():表示将偏差定义为常量0.\n",
    "    elif classname.find(\"BatchNorm1d\") != -1:               ## find():实现查找classname中是否含有BatchNorm2d字符，没有返回-1；有返回0.\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)     ## m.weight.data表示需要初始化的权重. nn.init.normal_():表示随机初始化采用正态分布，均值为0，标准差为0.02.\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)           ## nn.init.constant_():表示将偏差定义为常量0.\n",
    "\n",
    "##############################\n",
    "##  残差块儿ResidualBlock\n",
    "##############################\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(                     ## block = [pad + conv + norm + relu + pad + conv + norm]\n",
    "            nn.ReflectionPad1d(1),                      ## ReflectionPad2d():利用输入边界的反射来填充输入张量\n",
    "            nn.Conv1d(in_features, in_features, 3),     ## 卷积\n",
    "            nn.InstanceNorm1d(in_features),             ## InstanceNorm2d():在图像像素上对HW做归一化，用在风格化迁移\n",
    "            nn.ReLU(inplace=True),                      ## 非线性激活\n",
    "            nn.ReflectionPad1d(1),                      ## ReflectionPad2d():利用输入边界的反射来填充输入张量\n",
    "            nn.Conv1d(in_features, in_features, 3),     ## 卷积\n",
    "            nn.InstanceNorm1d(in_features),             ## InstanceNorm2d():在图像像素上对HW做归一化，用在风格化迁移\n",
    "        )\n",
    "\n",
    "    def forward(self, x):                               ## 输入为 一张图像\n",
    "        return x + self.block(x)                        ## 输出为 图像加上网络的残差输出\n",
    "\n",
    "##############################\n",
    "##  生成器网络GeneratorResNet\n",
    "##############################\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_blocks):   ## (input_shape = (1, 1024), num_residual_blocks = 9)\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "\n",
    "        channels = input_shape[0]                           ## 输入通道数channels = 3\n",
    "\n",
    "        ## 初始化网络结构\n",
    "        out_features = 64                                   ## 输出特征数out_features = 64 \n",
    "        model = [                                           ## model = [Pad + Conv + Norm + ReLU]\n",
    "            nn.ReflectionPad1d(channels),                   ## ReflectionPad2d(3):利用输入边界的反射来填充输入张量\n",
    "            nn.Conv1d(channels, out_features, 7, padding=3),           ## Conv2d(3, 64, 7)\n",
    "            nn.InstanceNorm1d(out_features),                ## InstanceNorm2d(64):在图像像素上对HW做归一化，用在风格化迁移\n",
    "            nn.ReLU(inplace=True),                          ## 非线性激活\n",
    "        ]\n",
    "        in_features = out_features                          ## in_features = 64\n",
    "\n",
    "        ## 下采样，循环2次\n",
    "        for _ in range(2):\n",
    "            out_features *= 2                                                   ## out_features = 128 -> 256\n",
    "            model += [                                                          ## (Conv + Norm + ReLU) * 2\n",
    "                nn.Conv1d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm1d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features                                          ## in_features = 256\n",
    "\n",
    "        # 残差块儿，循环9次\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(out_features)]                              ## model += [pad + conv + norm + relu + pad + conv + norm]\n",
    "\n",
    "        # 上采样两次\n",
    "        for _ in range(2):\n",
    "            out_features //= 2                                                  ## out_features = 128 -> 64\n",
    "            model += [                                                          ## model += [Upsample + conv + norm + relu]\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv1d(in_features, out_features, 3, stride=1, padding=1),\n",
    "                nn.InstanceNorm1d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features                                          ## out_features = 64\n",
    "\n",
    "        ## 网络输出层                                                            ## model += [pad + conv + tanh]\n",
    "        model += [nn.ReflectionPad1d(channels), nn.Conv1d(out_features, channels, 7), nn.Tanh()]    ## 将(3)的数据每一个都映射到[-1, 1]之间\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):           ## 输入(1, 3, 256, 256)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.model(x)\n",
    "        return x.squeeze(1)        ## 输出(1, 3, 256, 256)\n",
    "\n",
    "##############################\n",
    "#        Discriminator\n",
    "##############################\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):                                        \n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        channels, height = input_shape                                       ## input_shape:(3， 256， 256)\n",
    "\n",
    "        # Calculate output shape of image discriminator (PatchGAN)\n",
    "        self.output_shape = (1, height // 2 ** 4)                  ## output_shape = (1, 16, 16)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):           ## 鉴别器块儿\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv1d(in_filters, out_filters, 4, stride=2, padding=1)]   ## layer += [conv + norm + relu]    \n",
    "            if normalize:                                                           ## 每次卷积尺寸会缩小一半，共卷积了4次\n",
    "                layers.append(nn.InstanceNorm1d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(                                                 \n",
    "            *discriminator_block(channels, 64, normalize=False),        ## layer += [conv(3, 64) + relu]\n",
    "            *discriminator_block(64, 128),                              ## layer += [conv(64, 128) + norm + relu]\n",
    "            *discriminator_block(128, 256),                             ## layer += [conv(128, 256) + norm + relu]\n",
    "            *discriminator_block(256, 512),                             ## layer += [conv(256, 512) + norm + relu]\n",
    "            # nn.ZeroPad1d((1, 0, 1, 0)),                                 ## layer += [pad]\n",
    "            \n",
    "        )\n",
    "        self.model_conv = nn.Conv1d(512, 1, 4, padding=1)                             ## layer += [conv(512, 1)]\n",
    "\n",
    "    def forward(self, img):             ## 输入(1, 3, 256, 256)    \n",
    "        img = img.unsqueeze(1)\n",
    "        img = self.model(img)\n",
    "        img = F.pad(img, (1,0), \"constant\", 0)\n",
    "        return self.model_conv(img).squeeze(1)          ## 输出(1, 1, 16, 16)\n",
    "\n",
    "#########################################################################\n",
    "############################  utils.py  ###################################\n",
    "\n",
    "## 先前生成的样本的缓冲区\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        assert max_size > 0, \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):                       ## 放入一张图像，再从buffer里取一张出来\n",
    "        to_return = []                                  ## 确保数据的随机性，判断真假图片的鉴别器识别率\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:          ## 最多放入50张，没满就一直添加\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:          ## 满了就1/2的概率从buffer里取，或者就用当前的输入图片\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "\n",
    "\n",
    "## 设置学习率为初始学习率乘以给定lr_lambda函数的值\n",
    "class LambdaLR:                                \n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):                                                ## (n_epochs = 50, offset = epoch, decay_start_epoch = 30)\n",
    "        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"     ## 断言，要让n_epochs > decay_start_epoch 才可以\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):                                              ## return    1-max(0, epoch - 30) / (50 - 30)\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "############################  cycle_gan.py  ###################################\n",
    "\n",
    "## 超参数配置\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--epoch\", type=int, default=0, help=\"epoch to start training from\")\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=20, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--dataset_name\", type=str, default=\"dataset/facades\", help=\"name of the dataset\")## ../input/facades-dataset\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0003, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--decay_epoch\", type=int, default=3, help=\"epoch from which to start lr decay\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=2, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--img_height\", type=int, default=1024, help=\"size of image height\")\n",
    "parser.add_argument(\"--img_width\", type=int, default=256, help=\"size of image width\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=100, help=\"interval between saving generator outputs\")\n",
    "parser.add_argument(\"--checkpoint_interval\", type=int, default=-1, help=\"interval between saving model checkpoints\")\n",
    "parser.add_argument(\"--n_residual_blocks\", type=int, default=9, help=\"number of residual blocks in generator\")\n",
    "parser.add_argument(\"--lambda_cyc\", type=float, default=10.0, help=\"cycle loss weight\")\n",
    "parser.add_argument(\"--lambda_id\", type=float, default=5.0, help=\"identity loss weight\")\n",
    "# opt,unknow =parser.parse_know_args()\n",
    "opt = parser.parse_args(args=[])                 ## 在colab中运行时，换为此行\n",
    "print(opt)\n",
    "\n",
    "## 创建文件夹\n",
    "os.makedirs(\"images/%s\" % opt.dataset_name, exist_ok=True)\n",
    "os.makedirs(\"save/%s\" % opt.dataset_name, exist_ok=True)\n",
    "\n",
    "## input_shape:(1, 1024)\n",
    "input_shape = (opt.channels, opt.img_height)         \n",
    "\n",
    "## 创建生成器，判别器对象\n",
    "G_AB = GeneratorResNet(input_shape, opt.n_residual_blocks)\n",
    "G_BA = GeneratorResNet(input_shape, opt.n_residual_blocks)\n",
    "D_A = Discriminator(input_shape)\n",
    "D_B = Discriminator(input_shape)\n",
    "\n",
    "## 损失函数\n",
    "## MES 二分类的交叉熵\n",
    "## L1loss 相比于L2 Loss保边缘\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "## 如果有显卡，都在cuda模式中运行\n",
    "if torch.cuda.is_available():\n",
    "    G_AB = G_AB.cuda()\n",
    "    G_BA = G_BA.cuda()\n",
    "    D_A = D_A.cuda()\n",
    "    D_B = D_B.cuda()\n",
    "    criterion_GAN.cuda()\n",
    "    criterion_cycle.cuda()\n",
    "    criterion_identity.cuda()\n",
    "# print(G_AB)\n",
    "## 如果epoch == 0，初始化模型参数; 如果epoch == n, 载入训练到第n轮的预训练模型\n",
    "if opt.epoch != 0:\n",
    "    # 载入训练到第n轮的预训练模型\n",
    "    G_AB.load_state_dict(torch.load(\"save/%s/G_AB_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
    "    G_BA.load_state_dict(torch.load(\"save/%s/G_BA_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
    "    D_A.load_state_dict(torch.load(\"save/%s/D_A_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
    "    D_B.load_state_dict(torch.load(\"save/%s/D_B_%d.pth\" % (opt.dataset_name, opt.epoch)))\n",
    "else:\n",
    "    # 初始化模型参数\n",
    "    G_AB.apply(weights_init_normal)\n",
    "    G_BA.apply(weights_init_normal)\n",
    "    D_A.apply(weights_init_normal)\n",
    "    D_B.apply(weights_init_normal)\n",
    "\n",
    "\n",
    "## 定义优化函数,优化函数的学习率为0.0003\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2)\n",
    ")\n",
    "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "## 学习率更行进程\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",
    ")\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",
    ")\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",
    ")\n",
    "\n",
    "## 先前生成的样本的缓冲区\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "\n",
    "## 图像 transformations\n",
    "# transforms_ = [\n",
    "#     transforms.Resize(int(opt.img_height * 1.12)),   ## 图片放大1.12倍\n",
    "#     transforms.RandomCrop((opt.img_height, opt.img_width)),         ## 随机裁剪成原来的大小\n",
    "#     transforms.RandomHorizontalFlip(),                              ## 随机水平翻转\n",
    "#     transforms.ToTensor(),                                          ## 变为Tensor数据\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),         ## 正则化\n",
    "# ]\n",
    "\n",
    "## Training data loader \n",
    "dataloader = DataLoader(        ## 改成自己存放文件的目录\n",
    "    ImageDataset([\"data\"], unaligned=True),  ## \"./datasets/facades\" , unaligned:设置非对其数据\n",
    "    batch_size=opt.batch_size,                                                                  ## batch_size = 1\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu,\n",
    ")\n",
    "## Test data loader\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset([\"data\"], unaligned=True, mode=\"test\"), ## \"./datasets/facades\"\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "## 每间隔100次打印图片\n",
    "def sample_images(batches_done):      ## （100/200/300/400...）\n",
    "    \"\"\"保存测试集中生成的样本\"\"\"\n",
    "    imgs = next(iter(val_dataloader))      ## 取一张图像 \n",
    "    G_AB.eval()\n",
    "    G_BA.eval()\n",
    "    real_A = Variable(imgs[\"A\"]).cuda()    ## 取一张真A\n",
    "    fake_B = G_AB(real_A)                  ## 用真A生成假B\n",
    "    real_B = Variable(imgs[\"B\"]).cuda()    ## 去一张真B\n",
    "    fake_A = G_BA(real_B)                  ## 用真B生成假A\n",
    "    \n",
    "    fig ,ax=plt.subplots(5,4)\n",
    "    for i in range(5):\n",
    "        ax[i][0].plot(real_A.cpu()[i])\n",
    "        ax[i][1].plot(fake_B.cpu().detach().numpy()[i])\n",
    "        ax[i][2].plot(real_B.cpu()[i])\n",
    "        ax[i][3].plot(fake_A.cpu().detach().numpy()[i])\n",
    "    plt.savefig(\"images/%s/%s.png\" % (opt.dataset_name, batches_done))\n",
    "    # Arange images along x-axis\n",
    "    ## make_grid():用于把几个图像按照网格排列的方式绘制出来\n",
    "    # real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    # real_B = make_grid(real_B, nrow=5, normalize=True)\n",
    "    # fake_A = make_grid(fake_A, nrow=5, normalize=True)\n",
    "    # fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # # Arange images along y-axis\n",
    "    # ## 把以上图像都拼接起来，保存为一张大图片\n",
    "    # image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
    "    # save_image(image_grid, \"images/%s/%s.png\" % (opt.dataset_name, batches_done), normalize=False)\n",
    "\n",
    "\n",
    "def normalization(data):\n",
    "    return (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "def train():\n",
    "    # ----------\n",
    "    #  Training\n",
    "    # ----------\n",
    "    prev_time = time.time()                             ## 开始时间\n",
    "    for epoch in range(opt.epoch, opt.n_epochs):        ## for epoch in (0, 50)\n",
    "        for i, batch in enumerate(dataloader):          ## batch is a dict, batch['A']:(1, 3, 256, 256), batch['B']:(1, 3, 256, 256)\n",
    "    #       print('here is %d' % i)\n",
    "            ## 读取数据集中的真图片\n",
    "            ## 将tensor变成Variable放入计算图中，tensor变成variable之后才能进行反向传播求梯度\n",
    "            real_A = Variable(batch[\"A\"]).cuda()  ## 真图像A\n",
    "            real_B = Variable(batch[\"B\"]).cuda()  ## 真图像B\n",
    "\n",
    "            ## 全真，全假的标签\n",
    "            valid = Variable(torch.ones((real_A.size(0), *D_A.output_shape)), requires_grad=False).cuda()     ## 定义真实的图片label为1 ones((1, 1, 16, 16))\n",
    "            fake = Variable(torch.zeros((real_A.size(0), *D_A.output_shape)), requires_grad=False).cuda()     ## 定义假的图片的label为0 zeros((1, 1, 16, 16))\n",
    "            \n",
    "            \n",
    "            ## -----------------\n",
    "            ##  Train Generator\n",
    "            ## 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "            ## 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "            ## 反向传播更新的参数是生成网络里面的参数，\n",
    "            ## 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的, 这样就达到了对抗的目的\n",
    "            ## -----------------\n",
    "            G_AB.train()\n",
    "            G_BA.train()\n",
    "\n",
    "            ## Identity loss                                              ## A风格的图像 放在 B -> A 生成器中，生成的图像也要是 A风格\n",
    "            loss_id_A = criterion_identity(G_BA(real_A), real_A)          ## loss_id_A就是把图像A1放入 B2A 的生成器中，那当然生成图像A2的风格也得是A风格, 要让A1,A2的差距很小 \n",
    "            loss_id_B = criterion_identity(G_AB(real_B), real_B)\n",
    "\n",
    "            loss_identity = (loss_id_A + loss_id_B) / 2                   ## Identity loss \n",
    "\n",
    "            ## GAN loss\n",
    "            fake_B = G_AB(real_A)                                         ## 用真图像A生成的假图像B\n",
    "            loss_GAN_AB = criterion_GAN(D_B(fake_B), valid)               ## 用B鉴别器鉴别假图像B，训练生成器的目的就是要让鉴别器以为假的是真的，假的太接近真的让鉴别器分辨不出来\n",
    "            fake_A = G_BA(real_B)                                         ## 用真图像B生成的假图像A\n",
    "            loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)               ## 用A鉴别器鉴别假图像A，训练生成器的目的就是要让鉴别器以为假的是真的,假的太接近真的让鉴别器分辨不出来\n",
    "\n",
    "            loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2                    ## GAN loss\n",
    "\n",
    "            # Cycle loss 循环一致性损失                                                 \n",
    "            recov_A = G_BA(fake_B)                                        ## 之前中realA 通过 A -> B 生成的假图像B，再经过 B -> A ，使得fakeB 得到的循环图像recovA， \n",
    "            loss_cycle_A = criterion_cycle(recov_A, real_A)               ## realA和recovA的差距应该很小，以保证A,B间不仅风格有所变化，而且图片对应的的细节也可以保留\n",
    "            recov_B = G_AB(fake_A)\n",
    "            loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
    "\n",
    "            loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "\n",
    "            # Total loss                                                  ## 就是上面所有的损失都加起来\n",
    "            loss_G = loss_GAN + opt.lambda_cyc * loss_cycle + opt.lambda_id * loss_identity\n",
    "            optimizer_G.zero_grad()                                       ## 在反向传播之前，先将梯度归0\n",
    "            loss_G.backward()                                             ## 将误差反向传播\n",
    "            optimizer_G.step()                                            ## 更新参数\n",
    "          \n",
    "            \n",
    "            ## -----------------------\n",
    "            ## Train Discriminator A\n",
    "            ## 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "            ## -----------------------\n",
    "            ## 真的图像判别为真\n",
    "            loss_real = criterion_GAN(D_A(real_A), valid)\n",
    "            ## 假的图像判别为假(从之前的buffer缓存中随机取一张)\n",
    "            fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
    "            loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n",
    "            # Total loss\n",
    "            loss_D_A = (loss_real + loss_fake) / 2\n",
    "            optimizer_D_A.zero_grad()                                     ## 在反向传播之前，先将梯度归0\n",
    "            loss_D_A.backward()                                           ## 将误差反向传播\n",
    "            optimizer_D_A.step()                                          ## 更新参数\n",
    "            \n",
    "            ## -----------------------\n",
    "            ## Train Discriminator B\n",
    "            ## 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "            ## -----------------------\n",
    "            # 真的图像判别为真\n",
    "            loss_real = criterion_GAN(D_B(real_B), valid)                \n",
    "            ## 假的图像判别为假(从之前的buffer缓存中随机取一张)\n",
    "            fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n",
    "            loss_fake = criterion_GAN(D_B(fake_B_.detach()), fake)\n",
    "            # Total loss\n",
    "            loss_D_B = (loss_real + loss_fake) / 2\n",
    "            optimizer_D_B.zero_grad()                                     ## 在反向传播之前，先将梯度归0\n",
    "            loss_D_B.backward()                                           ## 将误差反向传播\n",
    "            optimizer_D_B.step()                                          ## 更新参数\n",
    "            loss_D = (loss_D_A + loss_D_B) / 2\n",
    "            \n",
    "            \n",
    "            ## ----------------------\n",
    "            ##  打印日志Log Progress\n",
    "            ## ----------------------\n",
    "\n",
    "            ## 确定剩下的大约时间  假设当前 epoch = 5， i = 100\n",
    "            batches_done = epoch * len(dataloader) + i                                        ## 已经训练了多长时间 5 * 400 + 100 次\n",
    "            batches_left = opt.n_epochs * len(dataloader) - batches_done                      ## 还剩下 50 * 400 - 2100 次\n",
    "            time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))  ## 还需要的时间 time_left = 剩下的次数 * 每次的时间\n",
    "            prev_time = time.time()\n",
    "            # Print log\n",
    "            sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    opt.n_epochs,\n",
    "                    i,\n",
    "                    len(dataloader),\n",
    "                    loss_D.item(),\n",
    "                    loss_G.item(),\n",
    "                    loss_GAN.item(),\n",
    "                    loss_cycle.item(),\n",
    "                    loss_identity.item(),\n",
    "                    time_left,\n",
    "                )\n",
    "            )\n",
    "            # 每训练100张就保存一组测试集中的图片\n",
    "            if batches_done % opt.sample_interval == 0:\n",
    "                sample_images(batches_done)\n",
    "\n",
    "        # 更新学习率\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_A.step()\n",
    "        lr_scheduler_D_B.step()\n",
    "\n",
    "        \n",
    "    ## 训练结束后，保存模型\n",
    "    torch.save(G_AB.state_dict(), \"save/%s/G_AB_%d.pth\" % (opt.dataset_name, epoch))\n",
    "    torch.save(G_BA.state_dict(), \"save/%s/G_BA_%d.pth\" % (opt.dataset_name, epoch))\n",
    "    torch.save(D_A.state_dict(), \"save/%s/D_A_%d.pth\" % (opt.dataset_name, epoch))\n",
    "    torch.save(D_B.state_dict(), \"save/%s/D_B_%d.pth\" % (opt.dataset_name, epoch))\n",
    "    print(\"\\nsave my model finished !!\")\n",
    "    #    ## 每间隔几个epoch保存一次模型\n",
    "    #     if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
    "    #         # Save model checkpoints\n",
    "    #         torch.save(G_AB.state_dict(), \"saved_models/%s/G_AB_%d.pth\" % (opt.dataset_name, epoch))\n",
    "    #         torch.save(G_BA.state_dict(), \"saved_models/%s/G_BA_%d.pth\" % (opt.dataset_name, epoch))\n",
    "    #         torch.save(D_A.state_dict(), \"saved_models/%s/D_A_%d.pth\" % (opt.dataset_name, epoch))\n",
    "    #         torch.save(D_B.state_dict(), \"saved_models/%s/D_B_%d.pth\" % (opt.dataset_name, epoch))\n",
    "\n",
    "\n",
    "def test():\n",
    "    ## 超参数设置\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batchSize', type=int, default=1, help='size of the batches')\n",
    "    parser.add_argument('--dataroot', type=str, default='dataset/facades', help='root directory of the dataset')\n",
    "    parser.add_argument('--channels', type=int, default=1, help='number of channels of input data')\n",
    "    parser.add_argument('--n_residual_blocks', type=int, default=9, help='number of channels of output data')\n",
    "    parser.add_argument('--size', type=int, default=1024, help='size of the data (squared assumed)')\n",
    "    parser.add_argument('--cuda', type=bool, default=True, help='use GPU computation')\n",
    "    parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "    parser.add_argument('--generator_A2B', type=str, default='save/dataset/facades/G_AB_19.pth', help='A2B generator checkpoint file')\n",
    "    parser.add_argument('--generator_B2A', type=str, default='save/dataset/facades/G_BA_19.pth', help='B2A generator checkpoint file')\n",
    "    # opt,unknow =parser.parse_know_args()\n",
    "    opt = parser.parse_args(args=[])                 ## 在colab中运行时，换为此行\n",
    "    print(opt)\n",
    "\n",
    "    #################################\n",
    "    ##          test准备工作        ##\n",
    "    #################################\n",
    "\n",
    "    ## input_shape:(1, 1024)\n",
    "    input_shape = (opt.channels, opt.size) \n",
    "    ## 创建生成器，判别器对象\n",
    "    netG_A2B = GeneratorResNet(input_shape, opt.n_residual_blocks)\n",
    "    netG_B2A = GeneratorResNet(input_shape, opt.n_residual_blocks)\n",
    "\n",
    "    ## 使用cuda\n",
    "    if opt.cuda:\n",
    "        netG_A2B.cuda()\n",
    "        netG_B2A.cuda()\n",
    "\n",
    "    ## 载入训练模型参数\n",
    "    netG_A2B.load_state_dict(torch.load(opt.generator_A2B))\n",
    "    netG_B2A.load_state_dict(torch.load(opt.generator_B2A))\n",
    "\n",
    "    ## 设置为测试模式\n",
    "    netG_A2B.eval()\n",
    "    netG_B2A.eval()\n",
    "\n",
    "    ## 创建一个tensor数组\n",
    "    Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "    input_A = Tensor(opt.batchSize, opt.channels, opt.size)\n",
    "    input_B = Tensor(opt.batchSize, opt.channels, opt.size)\n",
    "\n",
    "\n",
    "    '''构建测试数据集'''\n",
    "    # transforms_ = [ transforms.ToTensor(),\n",
    "    #                 transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "    dataloader = DataLoader(ImageDataset([\"data\"], mode='test'), \n",
    "                            batch_size=opt.batchSize, shuffle=False, num_workers=opt.n_cpu)\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    ##           test开始          ##\n",
    "    #################################\n",
    "\n",
    "    '''如果文件路径不存在, 则创建一个 (存放测试输出的图片)'''\n",
    "    if not os.path.exists('output/A'):\n",
    "        os.makedirs('output/A')\n",
    "    if not os.path.exists('output/B'):\n",
    "        os.makedirs('output/B')\n",
    "    \n",
    "    generated_clean = []\n",
    "    generated_noisy = []\n",
    "    counter = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        counter += 1\n",
    "        ## 输入数据 real\n",
    "        real_A = Variable(input_A.copy_(batch['A'])).squeeze(0)\n",
    "        real_B = Variable(input_B.copy_(batch['B'])).squeeze(0)\n",
    "        ## 通过生成器生成的 fake\n",
    "        fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "        fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
    "        # print(fake_A.cpu().numpy()[0])\n",
    "        \n",
    "        generated_clean.append(normalization(fake_A.cpu().numpy()[0]))\n",
    "        generated_noisy.append(normalization(fake_B.cpu().numpy()[0]))\n",
    "\n",
    "        if counter % 200 == 0:\n",
    "            np.save(str.format(\"data/generated_clean/{}\", counter // 200), np.array(generated_clean))\n",
    "            np.save(str.format(\"data/generated_noisy/{}\", counter // 200), np.array(generated_noisy))\n",
    "            generated_clean = []\n",
    "            generated_noisy = []\n",
    "        \n",
    "    print(\"测试完成\")\n",
    "\n",
    "\n",
    "## 函数的起始\n",
    "if __name__ == '__main__':\n",
    "    # train()  ## 训练\n",
    "    test()   ## 测试\n",
    "    pid = os.getpid()\n",
    "    !kill -9 $pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6b743-d7ca-4f04-b352-af3628f9426d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1DCNN",
   "language": "python",
   "name": "1dcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
